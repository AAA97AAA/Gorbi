{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import bz2\n",
    "import io\n",
    "from bz2 import BZ2File\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command is here to throw useless datas in files. Since we already reduced the files, there is no need to do the compression again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! for f in data/*[0-9].jsonl.bz2; do bzcat $f | jq -c '{id: .id, type: .tp, date: .d, title: .t, fulltext: .ft}' | bzip2 > \"{f%.jsonl.bz2}-reduced.jsonl.bz2\" ; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists the files in the current folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 718544\r\n",
      "drwxr-xr-x  15 aslam  staff       480  6 mar 00:06 \u001b[34m.\u001b[m\u001b[m/\r\n",
      "drwxrwxrwx  33 aslam  staff      1056  6 mar 00:06 \u001b[30m\u001b[43m..\u001b[m\u001b[m/\r\n",
      "-rwxrwxrwx   1 aslam  staff  23795907  3 mar 12:31 \u001b[31mJDG-1980-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  21521939  3 mar 12:32 \u001b[31mJDG-1981-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  22822888  3 mar 12:33 \u001b[31mJDG-1982-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  25263118  3 mar 12:34 \u001b[31mJDG-1983-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  23839962  3 mar 12:35 \u001b[31mJDG-1984-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  22984620  3 mar 12:36 \u001b[31mJDG-1985-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  33642024  3 mar 12:37 \u001b[31mJDG-1986-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  29476045  3 mar 12:38 \u001b[31mJDG-1987-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  33200405  3 mar 12:39 \u001b[31mJDG-1988-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  30297761  3 mar 12:40 \u001b[31mJDG-1989-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  32734001  3 mar 12:41 \u001b[31mJDG-1990-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  33790498  3 mar 12:43 \u001b[31mJDG-1991-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n",
      "-rwxrwxrwx   1 aslam  staff  34504639  3 mar 12:44 \u001b[31mJDG-1992-reduced.jsonl.bz2\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls -la data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading newspaper archive data\n",
    "\n",
    "Reminder: the data is already 'clean' and the files at hand contains only the following information:\n",
    "- id\n",
    "- date\n",
    "- title\n",
    "- type (article or advertisement)\n",
    "- fulltext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our reduced files are in data/, we need to have the path to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"data/\" # update with your path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function to get the lines from am archive\n",
    "def read_jsonlines(bz2_file):\n",
    "    text = bz2_file.read().decode('utf-8')\n",
    "    for line in text.split('\\n'):\n",
    "        if line != '':\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function to see if we have all the keywords contained in a list\n",
    "# returns true if all elements in arguments are positif\n",
    "def all_pos(myList):\n",
    "    return all(item > 0 for item in myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this helper function prints the text description, and the occurences corresponding to the keywords\n",
    "# This is only displaying content in the notebook \n",
    "# DEBUGGING PURPOSES (and for visualisation)\n",
    "def print_arrays(text_description, keywords, occurences):\n",
    "    myString = text_description + \" // \"\n",
    "    length = len(keywords)\n",
    "    \n",
    "    for i in range(0, length):\n",
    "        myString +=  keywords[i] + \": \" + str(occurences[i]) + \", \"\n",
    "    \n",
    "    print(myString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes:\n",
    "- article to study\n",
    "- keywords (list of keywords)\n",
    "\n",
    "and return:\n",
    "- the number of occurences of these words (sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function deals with an article and return the occurences (sum for all the keywords given) --> or condition\n",
    "# STAT PURPOSES\n",
    "def study(article, keywords):\n",
    "    json_article = json.loads(article)\n",
    "    full_text_str = json_article[\"fulltext\"].encode('ascii','ignore')\n",
    "    \n",
    "    flag = False # this flag will be True if at least one of the keyword is in the text\n",
    "    \n",
    "    length = len(keywords)\n",
    "    full_occurences = [0] * length\n",
    "    \n",
    "    for index in range(0, length):\n",
    "        occurences = len(re.findall(keywords[index], full_text_str, re.IGNORECASE))\n",
    "    \n",
    "        #title = json_article[\"id\"].encode('ascii','ignore')\n",
    "\n",
    "        if(occurences > 0):\n",
    "            flag = True\n",
    "            full_occurences[index] = occurences\n",
    "            \n",
    "    #if flag:\n",
    "            #print_arrays(title, keywords, full_occurences)\n",
    "            # Instead of print_arrays, we should call a function that will decide if all content are good or not\n",
    "            # a similar function will return sum of list (one \"or\" condition, and the and the \"and\" condition will be checked with all_pos)\n",
    "    return sum(full_occurences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes:\n",
    "    - dates (array of dates)\n",
    "    - myKeys (list of list of keywords: list of and condition, and or on each element of the list)\n",
    "    - andConditionVoc: which contains sum-up words for each element of myKeys\n",
    "\n",
    "\n",
    "returns:\n",
    "    - all the articles that verifies these conditions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns the articles that verifies three condition:\n",
    "#   - include in dates (dates can be list of years or list of \"YYYY-MM-DD\" )\n",
    "#   - myKeys (list of list of keywords: list of and condition, and or on each element of the list):\n",
    "        # [[\"Gorbatchev\", \"Gorbatchov\"], [\"Russie\", \"URSS\", \"Moscou\", \"soviétique\"], [\"politique\", \"économie\", \"PCUS\", \"Perestroika\", \"Glasnot\", \"Glasnost\"]]\n",
    "        # ([x, y, z] --> x AND y AND z)\n",
    "        # x = [x1, x2, x3] --> x1 OR x2 OR x3\n",
    "#   - andConditionVoc, which contains sum-up words for each element of myKeys\n",
    "        # [\"gorbatchev\", \"russians\", \"politics\"]\n",
    "    \n",
    "    \n",
    "def getArticles(dates, myKeys, andConditionVoc):\n",
    "    articles = []\n",
    "    for archive in os.listdir(input_dir):\n",
    "        print(archive)\n",
    "\n",
    "        # take only the transformed archives\n",
    "        if (\"reduced\" in archive):\n",
    "\n",
    "            # open the archive\n",
    "            f = BZ2File(os.path.join(input_dir, archive), 'r')\n",
    "\n",
    "            # get the list of articles it contains (= a json object on each line)\n",
    "            articles = list(read_jsonlines(f))\n",
    "            # load the first 100 articles as json and access their attributes\n",
    "            # print the size of each year\n",
    "            # print(\"size: \" + str(len(articles)))\n",
    "            for a in articles:\n",
    "\n",
    "                json_article = json.loads(a)\n",
    "                # id of the article\n",
    "                infos = json_article[\"id\"].encode('ascii','ignore')\n",
    "\n",
    "                occurencesPerDates = []\n",
    "                \n",
    "                for date in dates:\n",
    "                    occurencesOneYear = [] * len(andConditionVoc)\n",
    "\n",
    "                    if str(date) in infos:\n",
    "                        occurences = []\n",
    "                        for keywords in myKeys:\n",
    "                            occurences.append(study(a, keywords))\n",
    "\n",
    "                        occurencesOneYear += occurences\n",
    "                        \n",
    "                        if(all_pos(occurences)):\n",
    "                            # the following line prints details if needed\n",
    "                            # print_arrays(infos, andConditionVoc, occurences)\n",
    "                            articles.append(a)\n",
    "    return articles\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample code for articles retrieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDG-1987-reduced.jsonl.bz2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bec2d730da19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# get the articles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetArticles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyKeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mandConditionVoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# TODO: save them into a file compatible for IRAMUTEQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-aa4ced9c5bf6>\u001b[0m in \u001b[0;36mgetArticles\u001b[0;34m(dates, myKeys, andConditionVoc)\u001b[0m\n\u001b[1;32m     39\u001b[0m                         \u001b[0moccurences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyKeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                             \u001b[0moccurences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                         \u001b[0moccurencesOneYear\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moccurences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-29058fff2c2e>\u001b[0m in \u001b[0;36mstudy\u001b[0;34m(article, keywords)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moccurences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_text_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#title = json_article[\"id\"].encode('ascii','ignore')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@2/2.7.15_3/Frameworks/Python.framework/Versions/2.7/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexversion\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0x02020000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CODE TO OBTAINS ALL THE ARTICLES\n",
    "# defining the keywords \n",
    "# ([x, y, z] --> x AND y AND z)\n",
    "# x = [x1, x2, x3] --> x1 OR x2 OR x3\n",
    "myKeys = [[\"Gorbatchev\", \"Gorbatchov\"], [\"Russie\", \"URSS\", \"Moscou\", \"soviétique\"], [\"politique\", \"économie\", \"PCUS\", \"Perestroika\", \"Glasnot\", \"Glasnost\"]]\n",
    "# to be able to print with a single-word a bunch of words\n",
    "andConditionVoc = [\"gorbatchev\", \"russians\", \"politics\"]\n",
    "\n",
    "dates = range(1981, 1990)\n",
    "\n",
    "# get the articles\n",
    "print(len(getArticles(dates, myKeys, andConditionVoc)))\n",
    "\n",
    "# TODO: save them into a file compatible for IRAMUTEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAT PURPOSE\n",
    "# this function takes dates in input and a list of keywords\n",
    "# it will return the occurences depending the dates and the keywords\n",
    "# optimization: instead of checking the dates on each articles, we may prefer to just look at the archive year. \n",
    "# But in our case, we also want to have specific dates, so we must iterate over the articles\n",
    "def read_data(dates, keywords):\n",
    "    results = np.asarray([[0] * len(keywords)] * len(dates))\n",
    "    \n",
    "    for archive in os.listdir(input_dir):\n",
    "        print(archive)\n",
    "        # take only the transformed archives\n",
    "        # TODO: put \"reduced\" instead of \"1987\"\n",
    "        if (\"reduced\" in archive):\n",
    "\n",
    "            # open the archive\n",
    "            f = BZ2File(os.path.join(input_dir, archive), 'r')\n",
    "            # get the list of articles it contains (= a json object on each line)\n",
    "            articles = list(read_jsonlines(f))\n",
    "\n",
    "            for a in articles:\n",
    "\n",
    "                json_article = json.loads(a)\n",
    "                # id of the article\n",
    "                infos = json_article[\"id\"].encode('ascii','ignore')\n",
    "\n",
    "                for date_index in range(0, len(dates) ): # we need the date_index (date itself not enough)\n",
    "                    if str(dates[date_index]) in infos:\n",
    "                        occurences = np.asarray([0] * len(keywords))\n",
    "                        for keyword_index in range(0, len(keywords)):\n",
    "                            occurences[keyword_index] += study(a, keywords[keyword_index])\n",
    "                            \n",
    "                        results[date_index] += occurences\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "\n",
    "keywords = [\"gorbatchev\", \"russes\", \"politics\"]\n",
    "\n",
    "# dates = range(1981, 1990)\n",
    "dates = [\"1987-12-12\", \"1981-01-01\"]\n",
    "\n",
    "# print(read_data(dates, keywords))\n",
    "\n",
    "# return vector type = [[x1, y1, z1], [x2, y2, z2]]\n",
    "# 1 (or 2) --> date // x, y, z --> keywords\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus\n",
    "# This function is mostly coming from Group H (Secret Bancaire)\n",
    "def export(filename, list_articles):\n",
    "    return \"TODO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myKeys contain list of list of keywords ( [[\"Gorbatchev\", \"Gorbatchov\"], [\"Russie\", \"URSS\", \"Moscou\", \"soviétique\"], [\"politique\", \"économie\", \"PCUS\", \"Perestroika\", \"Glasnot\", \"Glasnost\"]])\n",
    "# STAT PURPOSES (Main function)\n",
    "# this will do a sum on each bunch of keywords (like OR), and if all_pos results --> accepted text\n",
    "\n",
    "def getOccurences(dates, myKeys):\n",
    "    result = np.asarray([[0] * len(dates)] * len(myKeys))\n",
    "\n",
    "    for key_index in range(0, len(myKeys)):\n",
    "        keywords = myKeys[key_index]\n",
    "        occurences_per_year = [sum(x) for x in read_data(dates, keywords)]\n",
    "        for date_index in range(0, len(dates)):\n",
    "            result[key_index][date_index] = occurences_per_year[date_index]\n",
    "        # print(result)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gives in string all the dates between two dates\n",
    "def string_dates(date1, date2):\n",
    "    result = []\n",
    "    delta = date2 - date1\n",
    "    \n",
    "    for i in range(delta.days + 1):\n",
    "        result.append(str(d1+timedelta(i)))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeFile(variableName, variable):\n",
    "    f = open(\"variables.txt\", \"a+\")\n",
    "    f.write(\"\\n\" + variableName + \"=\" + str(variable))\n",
    "    f.close()\n",
    "\n",
    "sample_result = [[0,0,0,0,44741811,48535429,77840706,55341914,35041383],\n",
    "                 [0,0,0,0,81038398,87802262,140905671,100246182,63635214],\n",
    "                 [0,0,0,0,144729853,157289618, 251367646,178893618,113408514]]\n",
    "# writeFile(\"lol\", sample_result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDG-1982-reduced.jsonl.bz2\n",
      "JDG-1987-reduced.jsonl.bz2\n",
      "JDG-1983-reduced.jsonl.bz2\n",
      "JDG-1986-reduced.jsonl.bz2\n",
      "JDG-1980-reduced.jsonl.bz2\n",
      "JDG-1985-reduced.jsonl.bz2\n",
      "JDG-1981-reduced.jsonl.bz2\n",
      "JDG-1984-reduced.jsonl.bz2\n",
      "JDG-1991-reduced.jsonl.bz2\n",
      "JDG-1988-reduced.jsonl.bz2\n",
      "JDG-1990-reduced.jsonl.bz2\n",
      "JDG-1989-reduced.jsonl.bz2\n",
      "JDG-1992-reduced.jsonl.bz2\n",
      "JDG-1982-reduced.jsonl.bz2\n",
      "JDG-1987-reduced.jsonl.bz2\n",
      "JDG-1983-reduced.jsonl.bz2\n",
      "JDG-1986-reduced.jsonl.bz2\n",
      "JDG-1980-reduced.jsonl.bz2\n",
      "JDG-1985-reduced.jsonl.bz2\n",
      "JDG-1981-reduced.jsonl.bz2\n",
      "JDG-1984-reduced.jsonl.bz2\n",
      "JDG-1991-reduced.jsonl.bz2\n",
      "JDG-1988-reduced.jsonl.bz2\n",
      "JDG-1990-reduced.jsonl.bz2\n",
      "JDG-1989-reduced.jsonl.bz2\n",
      "JDG-1992-reduced.jsonl.bz2\n",
      "JDG-1982-reduced.jsonl.bz2\n",
      "JDG-1987-reduced.jsonl.bz2\n",
      "JDG-1983-reduced.jsonl.bz2\n",
      "JDG-1986-reduced.jsonl.bz2\n",
      "JDG-1980-reduced.jsonl.bz2\n",
      "JDG-1985-reduced.jsonl.bz2\n",
      "JDG-1981-reduced.jsonl.bz2\n",
      "JDG-1984-reduced.jsonl.bz2\n",
      "JDG-1991-reduced.jsonl.bz2\n",
      "JDG-1988-reduced.jsonl.bz2\n",
      "JDG-1990-reduced.jsonl.bz2\n",
      "JDG-1989-reduced.jsonl.bz2\n",
      "JDG-1992-reduced.jsonl.bz2\n",
      "[[ 39983664  42547983  40467546  44664582  44741811  48535429  54084332\n",
      "   52077228  55418553]\n",
      " [ 71647562  76380469  73043605  80568047  81038398  87802262  97785994\n",
      "   93976916 100227099]\n",
      " [129024812 137402482 131373272 144449396 144729853 157289618 174568349\n",
      "  168772358 178871782]]\n",
      "corpus 1\n"
     ]
    }
   ],
   "source": [
    "# defining the keywords \n",
    "# ([x, y, z] --> x AND y AND z)\n",
    "# x = [x1, x2, x3] --> x1 OR x2 OR x3\n",
    "myKeys = [[\"Gorbatchev\", \"Gorbatchov\"], [\"Russie\", \"URSS\", \"Moscou\", \"soviétique\"], [\"politique\", \"économie\", \"PCUS\", \"Perestroika\", \"Glasnot\", \"Glasnost\"]]\n",
    "# to be able to print with a single-word a bunch of words\n",
    "andConditionVoc = [\"gorbatchev\", \"russians\", \"politique\"]\n",
    "\n",
    "dates = range(1981, 1990)\n",
    "# dates = [\"1987-12-12\", \"1988\"]\n",
    "\n",
    "\n",
    "corpus1_occurences = getOccurences(dates, myKeys)\n",
    "writeFile(\"corpus1_occurences\", corpus1_occurences)\n",
    "print(corpus1_occurences)\n",
    "print(\"corpus 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDG-1982-reduced.jsonl.bz2\n",
      "JDG-1987-reduced.jsonl.bz2\n",
      "JDG-1983-reduced.jsonl.bz2\n",
      "JDG-1986-reduced.jsonl.bz2\n",
      "JDG-1980-reduced.jsonl.bz2\n",
      "JDG-1985-reduced.jsonl.bz2\n",
      "JDG-1981-reduced.jsonl.bz2\n",
      "JDG-1984-reduced.jsonl.bz2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "myKeys = [[\"Reagan\"], [\"Etats-Unis\", \"USA\", \"Amerique\", \"Washington\"], [\"politique\", \"économie\", \"pershing\"]]\n",
    "# to be able to print with a single-word a bunch of words\n",
    "andConditionVoc = [\"Reagan\", \"USA\", \"politique\"]\n",
    "\n",
    "dates = range(1981, 1992)\n",
    "# dates = [\"1987-12-12\", \"1988\"]\n",
    "\n",
    "corpus2_occurences = getOccurences(dates, myKeys)\n",
    "writeFile(\"corpus2_occurences\", corpus2_occurences)\n",
    "print(corpus2_occurences)\n",
    "print(\"corpus 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDG-1987-reduced.jsonl.bz2\n",
      "GDL-1987-reduced.jsonl.bz2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-89ea64d7d148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcorpus3_occurences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetOccurences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyKeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# print(getOccurences(dates, myKeys))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-29eb5f7230d0>\u001b[0m in \u001b[0;36mgetOccurences\u001b[0;34m(dates, myKeys)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyKeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyKeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moccurences_per_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdate_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moccurences_per_year\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-d4a5885c3e27>\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(dates, keywords)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# get the list of articles it contains (= a json object on each line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0marticles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_jsonlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e54a34906517>\u001b[0m in \u001b[0;36mread_jsonlines\u001b[0;34m(bz2_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# a helper function to get the lines from am archive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_jsonlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbz2_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myKeys = [[\"Sommet\", \"Geneve\"], [\"Reagan\", \"Gorbatchev\", \"Gorbatchov\", \"Moscou\", \"Washington\"]]\n",
    "# to be able to print with a single-word a bunch of words\n",
    "andConditionVoc = [\"SommetGeneve\", \"voc\"]\n",
    "\n",
    "d1 = date(1985, 11, 13)\n",
    "d2 = date(1985, 11, 25)\n",
    "# dates = [\"1985-11-13\", \"1985-11-25\"]\n",
    "dates = string_dates(d1, d2)\n",
    "\n",
    "\n",
    "corpus3_occurences = getOccurences(dates, myKeys)\n",
    "writeFile(\"corpus3_occurences\", corpus3_occurences)\n",
    "print(corpus3_occurences)\n",
    "print(\"corpus 3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus 4\n"
     ]
    }
   ],
   "source": [
    "myKeys = [[\"Sommet\", \"Washington\"], [\"Reagan\", \"Gorbatchev\", \"Gorbatchov\", \"Moscou\", \"Washington\"]]\n",
    "# to be able to print with a single-word a bunch of words\n",
    "andConditionVoc = [\"SommetWashington\", \"voc\"]\n",
    "\n",
    "d1 = date(1987, 12, 02)\n",
    "d2 = date(1987, 12, 14)\n",
    "# dates = [\"1987-12-02\", \"1987-12-14\"]\n",
    "dates = string_dates(d1, d2)\n",
    "\n",
    "corpus4_occurences = getOccurences(dates, myKeys)\n",
    "writeFile(\"corpus4_occurences\", corpus4_occurences)\n",
    "print(corpus4_occurences)\n",
    "print(\"corpus 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus 5\n"
     ]
    }
   ],
   "source": [
    "myKeys = [[\"Gorbatchev\", \"Gorbatchov\"], [\"Russie\", \"URSS\", \"Moscou\", \"soviétique\"], [\"politique\", \"économie\", \"PCUS\", \"Perestroika\", \"Glasnot\", \"Glasnost\"],\n",
    "          [\"Reagan\"], [\"Etats-Unis\", \"USA\", \"Amerique\", \"Washington\"]\n",
    "         ]\n",
    "\n",
    "corpus5_occurences = getOccurences(dates, myKeys)\n",
    "writeFile(\"corpus5_occurences\", corpus5_occurences)\n",
    "print(\"corpus 5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-486c708bcff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# pd.DataFrame(dates, sample_result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'gorbatchev'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'russians'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'politics'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mandConditionVoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mandConditionVoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mandConditionVoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Ploting result with a Trial with a given result\n",
    "sample_result = [[0,0,0,0,44741811,48535429,77840706,55341914,35041383],\n",
    "                 [0,0,0,0,81038398,87802262,140905671,100246182,63635214],\n",
    "                 [0,0,0,0,144729853,157289618, 251367646,178893618,113408514]]\n",
    "\n",
    "\n",
    "dates = range(1981, 1990)\n",
    "dates = [1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989]\n",
    "\n",
    "andConditionVoc = [\"gorbatchev\", \"russians\", \"politics\"]\n",
    "\n",
    "# pd.DataFrame(dates, sample_result)\n",
    "\n",
    "pd.DataFrame({'gorbatchev': sample_result[0], 'russians': sample_result[1], 'politics': sample_result[2]}, index=dates)\n",
    "\n",
    "pd.DataFrame({andConditionVoc[0]: sample_result[0], andConditionVoc[1]: sample_result[1], andConditionVoc[2]: sample_result[2]}, index=dates)\n",
    "\n",
    "\n",
    "df.plot(kind=\"bar\").legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
